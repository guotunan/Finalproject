---
title: "Final Project"
author: "Tunan, Austin, Avi"
date: "Your Submission Date Here"
output: html_document
df_print: paged
---
# Alternate Grading System
## By Tunan, Austin, Avi

### 1. DATA

**Data History**

This data came from “OLI Elementary Chinese I” online course at Carnegie Mellon University from Jan 15, 2006 - Dec 11, 2006. “OLI”--Open Learning Initiative is a grant-funded group at Carnegie Mellon University, offering innovative online courses to anyone who wants to learn or teach. “Elementary Chinese I” aims to help beginners develop communicative competence in the basic four skills (listening, speaking, reading and writing) and culture of Chinese. The course curriculum is organized around the 5 Cs principles of the National Standards for Foreign Language Education for the 21st Century – Communication, Cultures, Comparisons, Connections and Communities. “Elementary Chinese I” covers 8 units. The principal investigator was Suemei Wu. 

**Data Description**

**General Info**

Number of students = 23, Number of unique steps = 255, Total number of steps = 3500, Total number of transactions = 6457, Total number of student hours = 38.51, Knowledge Component Models = 5 which are 1. Defalut(21 KCs) 2. Item model (255 KCs) 3. Single KC(1 KC) 4.Unique step(255 KCs) 5. Unique step new(255 KCs)

**Dataset info**

Row: Each row represents a specific question answered by a specific student

Column: There are total 33 columns. 

Row : Row no.
Sample : Sample of the data from where this dataset is selected here is is All data
Anon Student Id : Online Id generated by the student 
Problem Hierarchy : Unit and section to which problem belongs to
Problem Name : Unique name of the problem which is in the system
Problem View : Problem view no. Which is 1 for every row in this case
Problem Start Time: Start time of the problem along with date
Problem End Time : End time of the problem along with date
Latency (sec) : Time duration spent on that problem by the student
Steps Missing Start Times : This represents the no. of steps which are missing the start time recorded by the system
Hints : No. of hints  used
Incorrects : No. of incorrect answers submitted
Corrects :No. of correct answers submitted for that question
Avg Corrects :Average of number of correct answer submitted
Steps : No. of problem steps
Avg Assistance Score :Because the problems in this course were set as, if the answer was wrong, it would automatically provided hint and another attempt, this column is the combination of hints and incorrects. 
Correct First Attempts : If Correct answer submitted at first attempt (boolean)
Condition : blank column
KCs (Default) :No. of KCs from Default category
Steps without KCs (Default) : Steps without any KC from defalut category
KC List (Default) : List of KC from default category,specifies the name of the KC
KCs (Item Model): No. of KCs from Item Model category
Steps without KCs (Item Model): Steps without any KC from Item model category
KC List (Item Model):  List of KC from Item model category, specifies the name of the KC
KCs (Single-KC) : No. of KCs from Single KC category
Rest all of the columns related similar to the columns related to KCs as above.

### 2. QUESTION

**Can we develop a comprehensive grading system based on multiple factors instead of just numbers of correct answers and how is it different from the traditional grading system?**

### 3. APPROACH

**Many traditional grading system only use number of correct answers/total questions as the only factor to define students' performance. This causes a problem that most students are not accurately represented, especially in online courses where students can have multiple attempts and hints in each question. By taking the inspiration from math problems where, even if the answer is incorrect but the approach is, students can still earn partial credits. We developed a more comprehensive grading system by adding multiple factors in to see if we can give students a more accurate performance grade**


**To solve this problem our approach is that first we will calculate the base grade the normal way, in this case as the student is getting question correct after certain hints and attempts so we are calculating 'base grade'according to the number of questions got correct in first attempt and how many attempted. Then we will find a modified grade which wiil take not only these two factors but other factors as well. The model to calculate modified grade is as follows:**

If the student gets question right in 1st attempt = 1 point
If the student gets question right in 2nd attempt = 0.5 points
If the student gets question right in 3 or more attempts = 0 Points

Also

If the time taken per attempt is less than 12 secs( why?explained in the code below) bonus of 0.05 points, else 0

Then we will compare the grades of the students to see whether upto what extent these factors contribute to the new grading system.



### 4. PROCESS, RESULTS & INTEPRETATION
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages("readxl")
install.packages("knitr")
```


#Import data from excel
```{r}
#import "Originaldata.xlsx"
library(dplyr)
library(readxl)
Dataset1 <- read_excel("Originaldata.xlsx")
Dataset1
```

#Change certain variables from character to numeric for the later calculation purpose
```{r}
library(readxl)
Dataset2 <- read_excel("Originaldata.xlsx", 
    col_types = c("text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "numeric", "text", "numeric", "text", 
        "text", "text", "text", "numeric", 
        "numeric", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text"))
View(Dataset2)
```


#Change column names
```{r}
#When import the original dataset, the headers are somehow appear in the first row and the in the header row, it shows "x__1","x__2" all the way to "x__32".To change back the real headers, we rename each columns. 


colnames(Dataset2)<-c("Quesno.","Sample","AStuId","PH","PN","PV","PST","PET","Latency","SMST","Hints","Incorrects","Corrects","AvgCorrects","Steps","Attempts","Correct_in_First_Attempt","Condition","KCsD","SwKCsD","KClistD","KCsIM","SwKCsIM","KClistIM","KCsSKC","SwKCsSKC","KClistSKC","KCsUs","SwKCsUs","KClistUs","KCsUsn","SwKCsUsn","KClistUsn")
colnames(Dataset2)
Dataset2
```

#Delete the first row to avoid "n/a" error

```{r}
#After changing certain columns from character to numeric, the mislocated headers mention above (shown in the first row instead of in the header row) changed to "n/a". Also, after rename each column, there are two rows presenting the same content (headers). In order to successfully do calculation in later steps as well as avoid duplicated names, the first row need to be deleted. 

Dataset3 <- Dataset2[-c(1), ]
Dataset3
```


#Delete unrelated variables
```{r}
#based on team's former analysis, only save "Quesno.","AStuId", "Latency", "Hintsused","Attemptsused", "Correct_in_First_Attempt"

#Create a new dataset: Dataset4
Dataset4 <- select(Dataset3,Quesno.,AStuId, Latency, Hints, Attempts, Correct_in_First_Attempt)
Dataset4

```

#Finding the number of questions answered
```{r}

Dataset5 <- as.data.frame(table(Dataset4$AStuId))
names(Dataset5)[1] <- 'AStuId'
names(Dataset5)[2] <- 'Total_Questions_Answered'

```

#Finding the number of questions answered correctly in first attempt
```{r}
Dataset6 <- aggregate(Correct_in_First_Attempt~AStuId,data=Dataset4,FUN=sum)
```

#Calculating Base grade.Also a bit of more cleaning as we don't want big Anonymous student id's in our dataframe,so converting those id's to simple S1, S2, S3.. and so on
```{r}
Dataset7 <- merge(Dataset5, Dataset6, by="AStuId")
Dataset7 <- data.frame(lapply(Dataset7, as.character), stringsAsFactors=FALSE)
Dataset7$AStuId[Dataset7$AStuId=="Stu_08e80173bfe563cdaa1c51c3af183967"]<- "S1"
Dataset7$AStuId[Dataset7$AStuId=="Stu_0ca6c119fbc68309999c206abd6f6ce8"]<- "S2"
Dataset7$AStuId[Dataset7$AStuId=="Stu_20d015855bc9af67db1dc0feece33671"]<- "S3"
Dataset7$AStuId[Dataset7$AStuId=="Stu_29b6513f433dd556e3d2fd0c84ae1df7"]<- "S4"
Dataset7$AStuId[Dataset7$AStuId=="Stu_319a6ee2e48581a4911c6683ce38e66c"]<- "S5"
Dataset7$AStuId[Dataset7$AStuId=="Stu_38cc777ed5f1e4b1ee746787c3481d1c"]<- "S6"
Dataset7$AStuId[Dataset7$AStuId=="Stu_471da3aff346f24618e1b39a406a58cc"]<- "S7"
Dataset7$AStuId[Dataset7$AStuId=="Stu_537005374fa63386664e733eaa39a5e2"]<- "S8"
Dataset7$AStuId[Dataset7$AStuId=="Stu_5d32ab292b6894e8033f88d311c06934"]<- "S9"
Dataset7$AStuId[Dataset7$AStuId=="Stu_6f55653c379702a86c4cbf2f51223235"]<- "S10"
Dataset7$AStuId[Dataset7$AStuId=="Stu_76666c42b3bd62de26ef1075eeef2441"]<- "S11"
Dataset7$AStuId[Dataset7$AStuId=="Stu_77c9bcf1bd70d48b86557417affc8df5"]<- "S12"
Dataset7$AStuId[Dataset7$AStuId=="Stu_7c4f0c44b1530b231566e556afa1cdde"]<- "S13"
Dataset7$AStuId[Dataset7$AStuId=="Stu_7eeb4ea1ffb99f1ac3fed64192efd6d9"]<- "S14"
Dataset7$AStuId[Dataset7$AStuId=="Stu_82a5861804e0ea0912a99785eafdca34"]<- "S15"
Dataset7$AStuId[Dataset7$AStuId=="Stu_a641820befdca79ef8f74204af4bba6f"]<- "S16"
Dataset7$AStuId[Dataset7$AStuId=="Stu_ac395ff9f20429c1ecf7514e25c73f9a"]<- "S17"
Dataset7$AStuId[Dataset7$AStuId=="Stu_bdb07906752e4574c1a601326d4f4ec8"]<- "S18"
Dataset7$AStuId[Dataset7$AStuId=="Stu_c2dcd451a79cf7af8bc88a06e3c99f96"]<- "S19"
Dataset7$AStuId[Dataset7$AStuId=="Stu_c33a255f6fb92612765666934486c872"]<- "S20"
Dataset7$AStuId[Dataset7$AStuId=="Stu_d6c50e4a6ca0f6eee2ce1903ecc1a3e4"]<- "S21"
Dataset7$AStuId[Dataset7$AStuId=="Stu_f45af1c4bd5b0e6d14621a4fc92b48c7"]<- "S22"
Dataset7$AStuId[Dataset7$AStuId=="Stu_f50a6fe4716e01ce297055b1a6990d26"]<- "S23"

#
Dataset7[,2] <- as.numeric(as.character(Dataset7[,2]))
Dataset7[,3] <- as.numeric(as.character(Dataset7[,3]))
Dataset7$Percentage <- with(Dataset7 , (Percentage = Correct_in_First_Attempt/Total_Questions_Answered ))
```

```{r}
Dataset7$Grade <- ifelse(Dataset7$Percentage >=0.9, "A",ifelse(Dataset7$Percentage >=0.8,"B",ifelse(Dataset7$Percentage >=0.6 & Dataset7$Percentage>= 0.7 ,"C","D")))
Dataset7
```

#Now we will find the modfied grade considering the other factors as well. These factors will be attempts, average time taken per attempt
```{r}
#removing the rows where latency(time taken for question)is very high number. The high numbers are unusual cases. Unusual in the sense that student has either left the tab or some other reason.

D8 <- Dataset4
D8 <- subset(D8, Latency < 1000)
D8 <- data.frame(lapply(D8, as.character), stringsAsFactors=FALSE)
D8$AStuId[D8$AStuId=="Stu_08e80173bfe563cdaa1c51c3af183967"]<- "S1"
D8$AStuId[D8$AStuId=="Stu_0ca6c119fbc68309999c206abd6f6ce8"]<- "S2"
D8$AStuId[D8$AStuId=="Stu_20d015855bc9af67db1dc0feece33671"]<- "S3"
D8$AStuId[D8$AStuId=="Stu_29b6513f433dd556e3d2fd0c84ae1df7"]<- "S4"
D8$AStuId[D8$AStuId=="Stu_319a6ee2e48581a4911c6683ce38e66c"]<- "S5"
D8$AStuId[D8$AStuId=="Stu_38cc777ed5f1e4b1ee746787c3481d1c"]<- "S6"
D8$AStuId[D8$AStuId=="Stu_471da3aff346f24618e1b39a406a58cc"]<- "S7"
D8$AStuId[D8$AStuId=="Stu_537005374fa63386664e733eaa39a5e2"]<- "S8"
D8$AStuId[D8$AStuId=="Stu_5d32ab292b6894e8033f88d311c06934"]<- "S9"
D8$AStuId[D8$AStuId=="Stu_6f55653c379702a86c4cbf2f51223235"]<- "S10"
D8$AStuId[D8$AStuId=="Stu_76666c42b3bd62de26ef1075eeef2441"]<- "S11"
D8$AStuId[D8$AStuId=="Stu_77c9bcf1bd70d48b86557417affc8df5"]<- "S12"
D8$AStuId[D8$AStuId=="Stu_7c4f0c44b1530b231566e556afa1cdde"]<- "S13"
D8$AStuId[D8$AStuId=="Stu_7eeb4ea1ffb99f1ac3fed64192efd6d9"]<- "S14"
D8$AStuId[D8$AStuId=="Stu_82a5861804e0ea0912a99785eafdca34"]<- "S15"
D8$AStuId[D8$AStuId=="Stu_a641820befdca79ef8f74204af4bba6f"]<- "S16"
D8$AStuId[D8$AStuId=="Stu_ac395ff9f20429c1ecf7514e25c73f9a"]<- "S17"
D8$AStuId[D8$AStuId=="Stu_bdb07906752e4574c1a601326d4f4ec8"]<- "S18"
D8$AStuId[D8$AStuId=="Stu_c2dcd451a79cf7af8bc88a06e3c99f96"]<- "S19"
D8$AStuId[D8$AStuId=="Stu_c33a255f6fb92612765666934486c872"]<- "S20"
D8$AStuId[D8$AStuId=="Stu_d6c50e4a6ca0f6eee2ce1903ecc1a3e4"]<- "S21"
D8$AStuId[D8$AStuId=="Stu_f45af1c4bd5b0e6d14621a4fc92b48c7"]<- "S22"
D8$AStuId[D8$AStuId=="Stu_f50a6fe4716e01ce297055b1a6990d26"]<- "S23"
D8[,3] <- as.numeric(as.character(D8[,3]))
D8[,4] <- as.numeric(as.character(D8[,4]))
D8[,5] <- as.numeric(as.character(D8[,5]))
D8[,6] <- as.numeric(as.character(D8[,6]))

#Putting the no. of attempts in one column when the student has got question correct in first attempt.
D8$Attempts[D8$Correct_in_First_Attempt==1] <- 1
D8$timeperattempt <- with(D8, (timeperattempt = Latency/Attempts))
x <-median(D8$timeperattempt,na.rm = FALSE)
x
y <- mean(D8$timeperattempt,na.rm = FALSE)
y
#some values for 'timeperattempt' variable have come out to be 'zero' even though the student has got question right in the first attempt. This seems to be a bit odd. So considering the fact that student has got the question correct we are assigning that value to be median value, as we would be using 15 secs(which is close to median) as value to be the threshold value in our model to decide modified grade.

D8$timeperattempt[D8$timeperattempt==0] <- 12

w <-median(D8$Attempts,na.rm = FALSE)
z <- mean(D8$Attempts,na.rm = FALSE)

#summarising the no.of questions answered
D8_summary <-D
names(D8_summary)[2] <- 'modified_questions_answered'
```

```{r}
#Assigning modified score(Score1) based on number of attempts according to rule.
D8$Score1 <- NA
D8$Score1[D8$Attempts ==1] <-1
D8$Score1[D8$Attempts ==2] <-0.5
D8$Score1[D8$Attempts >=3] <-0
D8
```

```{r}
#Assigning modified score (score2) based on the timeperattempt variable according to the rule'if time per attempt is less than 15 secs then bonus of 0.2 points othewise no bonus points.'
D8$Score2 <- NA
D8$Score2[D8$timeperattempt <= 12] <-0.05
D8$Score2[D8$timeperattempt >12] <-0

#finding final score i.e score1 + score2

D8$finalmodifiedscore <- with(D8, (finalmodifiedscore = Score1 + Score2))
D9 <- aggregate(finalmodifiedscore~AStuId,data=D8,FUN=sum)

D1 <- aggregate(Attempts~AStuId,data=D8,FUN=mean)
names(D1)[2] <- 'meanattempts'
D2 <- aggregate(timeperattempt~AStuId,data=D8,FUN=mean)
names(D2)[2] <- 'meantimeperattempt'

D10 <- merge(D9,Dataset7,by="AStuId")
D10 <- merge(D10,D8_summary,by ="AStuId")
D10 <- merge(D10,D1, by ="AStuId")
D10 <- merge(D10,D2, by ="AStuId")

D10$modifiedPercentage <- with(D10, (modifiedpercentage = finalmodifiedscore/modified_questions_answered))

#finding final grade
D10$modifiedGrade <- ifelse(D10$modifiedPercentage >=0.9, "A",ifelse(D10$modifiedPercentage >=0.8,"B",ifelse(D10$modifiedPercentage >=0.6 & D10$modifiedPercentage>= 0.7 ,"C","D")))
D10 <- subset(D10, Total_Questions_Answered > 50)

```

```{r}
Dfinalcomparison <- D10
Dfinalcomparison
```
### 5. CONCLUSION: 

**Every student get a better grade. More students get “A”**

a)Traditional grade standard: two “A”s out of 16 students
b)New grade standard: twelve “A”s out of 16 students

**The reason why there are so many “A”s and why some students even moved from “D” to “A” is because: **

a)The new system team designed only add points to original scores, there is are no opportunities to reduce points. In another words, each student cannot get a worse grade than what they already had. 

b)The huge “jump” exists because team rewards students who gets correct answer on the second attempt, which means that besides their original score (correct at first attempts), they can add another 0.5 point in each of the remaining questions that being ignored by traditional grade standard. The more questions they answered, the more points they will have. For example, for S18, they had 158 questions correct at first attempts. But they answered 235 questions overall which means for every remaining question, as long as they got correct in two attempts, they could get extra 0.5 point per question. Although based on the table, it looks inappropriate by moving a student from “D” to “A”, but it is reasonable to give half points to students who got correct with second attempts. Team thought those students should be given partial credits and rewarded them by answering more questions. 

**Students’ performances can be better recognized**

Team also listed the mean number of attempts and the mean time in each attempt to show a general picture of how each student performed. Smaller numbers in both categories usually indicated the student had a better performance.

### 6. REFLECTION

We encountered several issues during the process: 

1. Finding the right data. Originally, we wanted to work with data from 538, but, while interesting, did not apply to learning analytics. Thanks to Avi, we started to work with data from Carnegie Mellon’s online courses.

2. Analyze the data to find weights (cut lines) in different variables. After identifying the variables team would use to develop a new grading system, we started deciding on the weights. Team calculated both mean and median of each variable and based on that, we tried both linear and nonlinear (parabola) lines to distribute our weights. The final decision we made was to use linear one because the distribution was simple and straightforward--1, 0.5, 0. There was no need to use a nonlinear method. 

3. Using the right functions. We encountered this issue several times and by google, asking instructors and discussing as a team, we managed to do all the necessary coding in R. 

4. Finding the best values to affect a students grade. Even after some changes and attempts, we found a relatively reasonable solution, the changes this new system made for some students (from C to A or D to A) still seemed inappropriate though we already explained why in the previous section. If team had more time, we would further optimize the system by maybe changing the grade standard or adding more standards (A-, B+, etc.). We also want to do a decision tree on figuring out which aspect of our new grading system have the most impact on helping a borderline student succeed and which have the least. 



